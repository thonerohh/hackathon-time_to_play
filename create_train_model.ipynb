{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce63281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as tfds\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B1\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7604287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start module from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f176cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part is only due to cyrillic characters issue in folder names reading on my mashine\n",
    "detail_names_list = ['CS120.01.413', 'CS120.07.442', 'CS150.01.427-01', 'SU160.00.404', 'SU80.01.426', 'SU80.10.409A', 'ЗВТ86.103К-02',\n",
    " 'СВМ.37.060', 'СВМ.37.060А', 'СВП-120.00.060', 'СВП120.42.020', 'СВП120.42.030', 'СК20.01.01.01.406',\n",
    " 'СК20.01.01.02.402', 'СК30.01.01.02.402', 'СК30.01.01.03.403', 'СК50.01.01.404', 'СК50.02.01.411', 'СПО250.14.190']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "219429cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\01',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\02',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\03',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\04',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\05',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\06',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\07',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\08',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\09',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\10',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\11',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\12',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\13',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\14',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\15',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\16',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\17',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\18',\n",
       " 'C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\19']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "data_dir = path +'\\\\dataset'\n",
    "#os.scandir\n",
    "#from glob import glob\n",
    "#glob('C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\dataset\\\\*', recursive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7f14eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1541 files belonging to 19 classes.\n",
      "Using 1233 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "\n",
    "train_ds1 = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  crop_to_aspect_ratio=True,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe35d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1541 files belonging to 19 classes.\n",
      "Using 308 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds1 = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e81cef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds1.class_names\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6041da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91019927",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds1 = train_ds1.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds1 = val_ds1.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16e849e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    start_from_epoch=10,\n",
    "    patience=4\n",
    ")\n",
    "model_save = tf.keras.callbacks.ModelCheckpoint(\n",
    "    path,\n",
    "    save_best_only = True,\n",
    ")\n",
    "callbacks = [early_stop,model_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4273251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.1715 - accuracy: 0.6521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 138s 3s/step - loss: 1.1715 - accuracy: 0.6521 - val_loss: 0.6482 - val_accuracy: 0.7760\n",
      "Epoch 2/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 132s 3s/step - loss: 0.3655 - accuracy: 0.8670 - val_loss: 0.5528 - val_accuracy: 0.8247\n",
      "Epoch 3/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 130s 3s/step - loss: 0.2098 - accuracy: 0.9359 - val_loss: 0.4077 - val_accuracy: 0.8766\n",
      "Epoch 4/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 131s 3s/step - loss: 0.1549 - accuracy: 0.9530 - val_loss: 0.3583 - val_accuracy: 0.8961\n",
      "Epoch 5/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 133s 3s/step - loss: 0.1009 - accuracy: 0.9716 - val_loss: 0.3168 - val_accuracy: 0.8896\n",
      "Epoch 6/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 130s 3s/step - loss: 0.0912 - accuracy: 0.9749 - val_loss: 0.2909 - val_accuracy: 0.9026\n",
      "Epoch 7/40\n",
      "39/39 [==============================] - 94s 2s/step - loss: 0.0906 - accuracy: 0.9700 - val_loss: 0.3181 - val_accuracy: 0.8831\n",
      "Epoch 8/40\n",
      "39/39 [==============================] - 94s 2s/step - loss: 0.0625 - accuracy: 0.9797 - val_loss: 0.3584 - val_accuracy: 0.8766\n",
      "Epoch 9/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 137s 4s/step - loss: 0.0575 - accuracy: 0.9830 - val_loss: 0.2573 - val_accuracy: 0.8929\n",
      "Epoch 10/40\n",
      "39/39 [==============================] - 89s 2s/step - loss: 0.0410 - accuracy: 0.9895 - val_loss: 0.3318 - val_accuracy: 0.8896\n",
      "Epoch 11/40\n",
      "39/39 [==============================] - 89s 2s/step - loss: 0.0400 - accuracy: 0.9911 - val_loss: 0.3973 - val_accuracy: 0.8734\n",
      "Epoch 12/40\n",
      "39/39 [==============================] - 90s 2s/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.3256 - val_accuracy: 0.8831\n",
      "Epoch 13/40\n",
      "39/39 [==============================] - 89s 2s/step - loss: 0.0400 - accuracy: 0.9862 - val_loss: 0.3966 - val_accuracy: 0.8864\n",
      "Epoch 14/40\n",
      "39/39 [==============================] - 89s 2s/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.3851 - val_accuracy: 0.8831\n",
      "Epoch 15/40\n",
      "39/39 [==============================] - 89s 2s/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.2655 - val_accuracy: 0.9091\n",
      "Epoch 16/40\n",
      "39/39 [==============================] - 89s 2s/step - loss: 0.0304 - accuracy: 0.9927 - val_loss: 0.4261 - val_accuracy: 0.8896\n",
      "Epoch 17/40\n",
      "39/39 [==============================] - 89s 2s/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.3762 - val_accuracy: 0.8994\n",
      "Epoch 18/40\n",
      "39/39 [==============================] - 89s 2s/step - loss: 0.0330 - accuracy: 0.9903 - val_loss: 0.4696 - val_accuracy: 0.8799\n",
      "Epoch 19/40\n",
      "39/39 [==============================] - 89s 2s/step - loss: 0.0387 - accuracy: 0.9862 - val_loss: 0.4350 - val_accuracy: 0.8896\n",
      "Epoch 1/40\n",
      "39/39 [==============================] - 170s 4s/step - loss: 0.2500 - accuracy: 0.9473 - val_loss: 0.2602 - val_accuracy: 0.8961\n",
      "Epoch 2/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 195s 5s/step - loss: 0.0501 - accuracy: 0.9968 - val_loss: 0.2461 - val_accuracy: 0.9156\n",
      "Epoch 3/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 235s 6s/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9221\n",
      "Epoch 4/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 242s 6s/step - loss: 0.0168 - accuracy: 0.9976 - val_loss: 0.2132 - val_accuracy: 0.9253\n",
      "Epoch 5/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 236s 6s/step - loss: 0.0122 - accuracy: 0.9992 - val_loss: 0.2122 - val_accuracy: 0.9383\n",
      "Epoch 6/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 242s 6s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9351\n",
      "Epoch 7/40\n",
      "39/39 [==============================] - 191s 5s/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.2199 - val_accuracy: 0.9448\n",
      "Epoch 8/40\n",
      "39/39 [==============================] - 191s 5s/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.2199 - val_accuracy: 0.9351\n",
      "Epoch 9/40\n",
      "39/39 [==============================] - 191s 5s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9383\n",
      "Epoch 10/40\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 112). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Gliwork\\Desktop\\0-Rojects\\2023 Khabarovsk hackaton\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 236s 6s/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.1946 - val_accuracy: 0.9286\n",
      "Epoch 11/40\n",
      "39/39 [==============================] - 195s 5s/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.2165 - val_accuracy: 0.9416\n",
      "Epoch 12/40\n",
      "39/39 [==============================] - 196s 5s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9318\n",
      "Epoch 13/40\n",
      "39/39 [==============================] - 197s 5s/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.2279 - val_accuracy: 0.9383\n",
      "Epoch 14/40\n",
      "39/39 [==============================] - 197s 5s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9416\n",
      "Epoch 15/40\n",
      "39/39 [==============================] - 195s 5s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9448\n",
      "Epoch 16/40\n",
      "39/39 [==============================] - 196s 5s/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.2090 - val_accuracy: 0.9448\n",
      "Epoch 17/40\n",
      "39/39 [==============================] - 194s 5s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9416\n",
      "Epoch 18/40\n",
      "39/39 [==============================] - 194s 5s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9416\n",
      "Epoch 19/40\n",
      "39/39 [==============================] - 194s 5s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9383\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = EfficientNetV2B1(weights='imagenet', include_top=False, input_shape = (img_height, img_width, 3))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),#from_logits=True\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "history = model.fit(\n",
    "    train_ds1,\n",
    "    validation_data=val_ds1,\n",
    "    epochs=epochs, callbacks=[callbacks])\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "#for i, layer in enumerate(base_model.layers):\n",
    "#   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:198]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[198:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001,\n",
    "    ema_momentum=0.95),\n",
    "    #SGD(learning_rate=0.0001, momentum=0.9), \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),#from_logits=True\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "history1 = model.fit(\n",
    "    train_ds1,\n",
    "    validation_data=val_ds1,\n",
    "    epochs=epochs, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "805793e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (40,) and (19,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining Accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs_range, val_acc, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower right\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf-cpu\\Lib\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf-cpu\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf-cpu\\Lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf-cpu\\Lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (40,) and (19,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1112a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history1.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59c6b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('C:\\\\Users\\\\Gliwork\\\\Desktop\\\\0-Rojects\\\\2023 Khabarovsk hackaton\\\\efficientnet_model.keras')\n",
    "model.save(path+'\\\\efficientnet_40_epochs_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0847f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = os.getcwd()\n",
    "prediction_folder = path + '\\\\prediction'\n",
    "folder = prediction_folder + '\\\\*'\n",
    "#os.scandir\n",
    "#from glob import glob\n",
    "files = glob(folder, recursive = True)\n",
    "#folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b15cbb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "IMG_20230920_142557.jpg  -  9 ( СВП-120.00.060 )\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "IMG_20230920_142620.jpg  -  9 ( СВП-120.00.060 )\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "IMG_20230920_142632.jpg  -  9 ( СВП-120.00.060 )\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "IMG_20230920_142640.jpg  -  9 ( СВП-120.00.060 )\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "IMG_20230920_142656.jpg  -  9 ( СВП-120.00.060 )\n"
     ]
    }
   ],
   "source": [
    "files = glob(folder, recursive = True)\n",
    "for image_path in files:\n",
    "    image = tf.keras.utils.load_img(image_path)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    input_arr = tf.keras.utils.img_to_array(image)\n",
    "    predictions = model.predict(np.array([input_arr]))#(normalized_input_arr)\n",
    "    print(image_path[image_path.rfind('\\\\')+1:], ' - ',np.argmax(predictions), '(',detail_names_list[np.argmax(predictions)],')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3037e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c638ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
